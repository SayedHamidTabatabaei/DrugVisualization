
\appendixchapter{معیارهای ارزیابی}
% \addcontentsline{toc}{chapter}{معیارهای ارزیابی}
\label{appendix:evaluations}



برای ارزیابی عملکرد مدل‌های یادگیری ماشین در وظایف طبقه‌بندی، استفاده از معیارهای ارزیابی مناسب ضروری است. این معیارها به ما امکان می‌دهند تا توانایی مدل‌ها را در شناسایی درست و دقیق نمونه‌ها، و همچنین عملکرد آن‌ها را در موارد مختلف، مانند داده‌های نامتوازن، ارزیابی کنیم. در این پژوهش، از دو معیار اصلی دقت و امتیاز F1 برای ارزیابی عملکرد مدل استفاده شده است. معیار \lr{F1-Score} که از ترکیب دو معیار بازخوانی\LTRfootnote{Recall} و صحت\LTRfootnote{Precision} محاسبه می‌شود، به تنهایی می‌تواند گویای عملکرد مدل از هر دو جنبه باشد؛ به همین دلیل، به جای نمایش جداگانه مقادیر این دو معیار، تنها نتایج \lr{F1-Score} در متن اصلی پایان‌نامه ارائه شده است. در این پیوست، نحوه محاسبه و تفسیر این معیارها توضیح داده می‌شود. درک عمیق این معیارها و نحوه به‌کارگیری آن‌ها، گامی اساسی در ارزیابی و بهبود عملکرد مدل‌های یادگیری ماشین در انواع مسائل طبقه‌بندی است.

\section{دقت}
\label{appendix:accuracy}

دقت یکی از معیارهای پایه‌ای و پرکاربرد در ارزیابی عملکرد مدل‌های طبقه‌بندی است. این معیار نشان می‌دهد که مدل چه نسبتی از کل نمونه‌ها را به‌درستی طبقه‌بندی کرده است. به عبارت دیگر، دقت بیانگر نزدیکی پیش‌بینی‌های مدل به برچسب‌های واقعی نمونه‌ها است \cite{ref_sokolova2009}. فرمول محاسبه این معیار به صورت زیر است:
\begin{equation}
	\text{Accuracy} = \frac{\text{TP} + \text{TN}}{\text{TP} + \text{TN} + \text{FP} + \text{FN}}
\end{equation}

\begin{itemize}
\item \textbf{\LR{True Positives (TP)}}: نمونه‌هایی که مدل به‌درستی آن‌ها را به‌عنوان کلاس مثبت پیش‌بینی کرده است.
\item \textbf{\LR{True Negatives (TN)}}: نمونه‌هایی که مدل به‌درستی آن‌ها را به‌عنوان کلاس منفی پیش‌بینی کرده است.
\item \textbf{\LR{False Positives (FP)}}: نمونه‌هایی که مدل نتواسته است آن‌ها را به‌عنوان کلاس منفی پیش‌بینی کند.
\item \textbf{\LR{False Negatives (FN)}}: نمونه‌هایی که مدل نتواسته است آن‌ها را به‌عنوان کلاس مثبت پیش‌بینی کند.
\end{itemize}

مقادیر بالای دقت نشان می‌دهند که مدل در طبقه‌بندی صحیح نمونه‌ها در کلاس‌های مختلف عملکرد خوبی دارد. این موضوع در کاربردهایی که نیازمند تشخیص دقیق نمونه‌ها هستند، مانند شناسایی تداخلات دارویی، اهمیت ویژه‌ای دارد. با این حال، دقت معیاری است که در شرایط خاص، مانند داده‌های بسیار نامتوازن، ممکن است به‌تنهایی گمراه‌کننده باشد. برای مثال، در یک مسئله طبقه‌بندی با نسبت 95 به 5 بین کلاس‌های منفی و مثبت، مدلی که همه نمونه‌ها را منفی پیش‌بینی کند، دقت 95٪ خواهد داشت، اما در عمل کارایی مناسبی ندارد. بنابراین، برای غلبه بر این محدودیت و درک جامع‌تر عملکرد مدل، دقت را باید در کنار سایر معیارها مانند \lr{F1-Score} مورد بررسی قرار داد \cite{ref_sokolova2009, ref_powers2011}.

\subsubsection{کاربرد دقت در پروژه شناسایی تداخلات دارویی}
در پروژه شناسایی تداخلات دارویی، با وجود احتمال نامتوازن بودن داده‌ها، دقت هنوز هم یک معیار مهم برای ارزیابی عملکرد کلی مدل محسوب می‌شود، اما برای درک دقیق‌تر نقاط قوت و ضعف مدل، باید دقت را در کنار معیار \lr{F1-Score} تحلیل کرد \cite{ref_sokolova2009}. از طرفی با بررسی مقادیر دقت محاسبه شده برای هر یک از 65 نوع تداخل دارویی، می‌توان انواعی از تداخلات را که مدل در طبقه‌بندی صحیح آن‌ها عملکرد ضعیف‌تری دارد شناسایی کرد و با تمرکز بر بهبود شناسایی این انواع خاص از تداخلات، به ارتقای کارایی کلی سیستم در شناسایی تداخلات دارویی کمک نمود؛ این بهبود عملکرد را می‌توان با اقداماتی مانند جمع‌آوری داده‌های بیشتر برای آن کلاس‌های خاص، بهینه‌سازی ویژگی‌های مورد استفاده، یا به‌کارگیری تکنیک‌های نمونه‌برداری مجدد محقق ساخت.

\section{بازخوانی}

بازخوانی معیاری است برای اندازه‌گیری توانایی مدل در شناسایی صحیح موارد مثبت. این معیار نسبت نمونه‌های واقعی مثبت را که به‌درستی به‌عنوان مثبت توسط مدل پیش‌بینی شده‌اند، محاسبه می‌کند \cite{ref_powers2011}. فرمول محاسبه این معیار به صورت زیر است:

\begin{equation}
	\text{Recall} = \frac{\text{\LR{True Positives (TP)}}}{\text{\LR{True Positives (TP)}} + \text{\LR{False Negatives (FN)}}}
\end{equation}

\begin{itemize}
	\item \textbf{\LR{True Positives (TP)}}: نمونه‌هایی که مدل به‌درستی آن‌ها را به‌عنوان کلاس مثبت پیش‌بینی کرده است.
	\item \textbf{\LR{False Negatives (FN)}}: نمونه‌هایی که مدل نتواسته است آن‌ها را به‌عنوان کلاس مثبت پیش‌بینی کند.
\end{itemize}

\subsubsection{انواع بازخوانی برای مسائل چندکلاسی}


برای مسائل \textbf{چندکلاسی}، \textbf{بازخوانی} می‌تواند با استفاده از روش‌های مختلف تجمیع محاسبه شود:

\begin{itemize}
	\item \textbf{\LR{Micro Recall}}: در این روش، \textbf{\LR{True Positives}} و \textbf{\LR{False Negatives}} در تمامی کلاس‌ها تجمیع شده و یک مقدار واحد به‌طور کلی محاسبه می‌شود. این روش زمانی مناسب است که می‌خواهیم عملکرد کلی مدل را بدون توجه به اندازه کلاس‌ها مورد ارزیابی قرار دهیم \cite{ref_sokolova2009}. فرمول این روش به صورت زیر است:
	\begin{equation}
		Recall_{Micro} = \frac{\sum \text{\LR{True Positives}}}{\sum (\text{\LR{True Positives}} + \text{\LR{False Negatives}})}
	\end{equation}
	
	\item \textbf{\LR{Macro Recall}}: در این روش، \textbf{بازخوانی} برای هر کلاس به‌طور جداگانه محاسبه شده و سپس میانگین آن‌ها گرفته می‌شود. این روش زمانی مناسب است که می‌خواهیم عملکرد متوسط مدل را در تمامی کلاس‌ها مورد ارزیابی قرار دهیم و تمامی کلاس‌ها دارای اهمیت یکسان باشند \cite{ref_sokolova2009}. فرمول این روش به صورت زیر است:
	\begin{equation}
		Recall_{Macro} = \frac{1}{N} \sum_{i=1}^{N} \text{Recall}_i
	\end{equation}
	
	که در آن \( N \) تعداد کلاس‌ها است.
	
	\item \textbf{\LR{Weighted Recall}}: در این روش، \textbf{بازخوانی} برای هر کلاس به‌طور جداگانه محاسبه شده و سپس میانگین آن‌ها با وزن‌دهی به تعداد نمونه‌های صحیح در هر کلاس محاسبه می‌شود. این روش زمانی مناسب است که نیاز به در نظر گرفتن عدم تعادل کلاس‌ها وجود دارد و بایستی به کلاس‌های بزرگ‌تر اهمیت بیشتری داده شود \cite{ref_sokolova2009}. فرمول این روش به صورت زیر است:
	\begin{equation}
		Recall_{Weighted} = \sum_{i=1}^{N} w_i \cdot \text{Recall}_i
	\end{equation}
	
	که در آن \( w_i \) نسبت نمونه‌های کلاس \( i \) است.
	
\end{itemize}

مقایسه مقادیر \LR{Micro Recall}، \LR{Macro Recall} و \LR{Weighted Recall} می‌تواند بینش ارزشمندی در مورد عملکرد مدل در شناسایی نمونه‌های مثبت در کلاس‌های مختلف ارائه دهد. تفاوت قابل توجه بین این معیارها می‌تواند نشان‌دهنده عملکرد نامتوازن مدل در کلاس‌های مختلف باشد.

\section{صحت}
صحت معیاری است برای ارزیابی دقت پیش‌بینی‌های مثبت در مسائل طبقه‌بندی و نسبت پیش‌بینی‌های مثبت صحیح را از میان تمامی پیش‌بینی‌های مثبت انجام‌شده توسط مدل محاسبه می‌کند. این معیار به‌ویژه در شرایطی که پیش‌بینی‌های مثبت نادرست هزینه بالایی دارند، از اهمیت ویژه‌ای برخوردار است \cite{ref_powers2011}. فرمول محاسبه این معیار به‌صورت زیر است:

\begin{equation}
	Precision = \frac{\text{\LR{True Positives (TP)}}}{\text{\LR{True Positives (TP)}} + \text{\LR{False Positives (FP)}}}
\end{equation}

\begin{itemize}
	\item \textbf{\LR{True Positives (TP)}}: نمونه‌هایی که مدل به‌درستی آن‌ها را به‌عنوان کلاس مثبت پیش‌بینی کرده است.
	\item \textbf{\LR{False Positives (FP)}}: نمونه‌هایی که مدل به‌طور اشتباه آن‌ها را به‌عنوان کلاس مثبت پیش‌بینی کرده است.
\end{itemize}

\subsubsection{انواع صحت برای مسائل چندکلاسی}

برای مسائل \textbf{چندکلاسی}، \textbf{صحت} می‌تواند با استفاده از روش‌های مختلف تجمیع محاسبه شود:

\begin{itemize}
	\item \textbf{\LR{Micro Precision}}: در این روش، \textbf{\LR{True Positives}} و \textbf{\LR{False Positives}} در تمامی کلاس‌ها تجمیع شده و یک مقدار واحد به‌طور کلی محاسبه می‌شود. این روش زمانی مناسب است که می‌خواهیم عملکرد کلی مدل را بدون آنکه بر تعادل کلاس‌ها تاکید داشته باشیم، ارزیابی کنیم \cite{ref_sokolova2009}.
	\begin{equation}
		Precision_{Micro} = \frac{\sum \text{\LR{True Positives}}}{\sum (\text{\LR{True Positives}} + \text{\LR{False Positives}})}
	\end{equation}
	\item \textbf{\LR{Macro Precision}}: در این روش، \textbf{صحت} برای هر کلاس به‌طور جداگانه محاسبه شده و سپس میانگین آن‌ها گرفته می‌شود. این روش زمانی مناسب است که می‌خواهیم عملکرد مدل را به‌طور مساوی در تمامی کلاس‌ها ارزیابی کنیم \cite{ref_sokolova2009}.
	\begin{equation}
		Precision_{Macro} = \frac{1}{N} \sum_{i=1}^{N} \text{Precision}_i
	\end{equation}
	
	که در آن \( N \) تعداد کلاس‌ها است.
	
	\item \textbf{\LR{Weighted Precision}}: در این روش، \textbf{صحت} برای هر کلاس به‌طور جداگانه محاسبه شده و سپس میانگین آن‌ها با وزن‌دهی به تعداد نمونه‌های صحیح در هر کلاس محاسبه می‌شود. این روش زمانی مناسب است که می‌خواهیم عدم تعادل کلاس‌ها را در نظر گرفته و کلاس‌های بزرگ‌تر تاثیر بیشتری در ارزیابی کلی داشته باشند \cite{ref_sokolova2009}.
	\begin{equation}
		Precision_{Weighted} = \sum_{i=1}^{N} w_i \cdot \text{Precision}_i
	\end{equation}
	
	که در آن \( w_i \) نسبت نمونه‌های کلاس \( i \) است.
\end{itemize}

بررسی مقادیر \LR{Micro Precision}، \LR{Macro Precision} و \LR{Weighted Precision} می‌تواند درک بهتری از عملکرد مدل در پیش‌بینی صحیح نمونه‌های مثبت در هر کلاس فراهم کند. اختلاف زیاد بین این معیارها می‌تواند بیانگر عملکرد متفاوت مدل در کلاس‌های گوناگون باشد.

\section{امتیاز F1}

امتیاز F1 یک معیار اندازه‌گیری عملکرد مدل است که در مسائل طبقه‌بندی با داده‌های نامتوازن بسیار مفید است. این معیار به‌طور همزمان مقادیر به دست آمده در معیارهای صحت و بازخوانی را در نظر می‌گیرد و میانگین هارمونیک این دو معیار را محاسبه می‌کند، که تعادلی بین این دو ایجاد می‌کند. فرمول محاسبه این معیار به شکل زیر است \cite{ref_manning2008}:
\begin{equation}
	F1 = 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}
\end{equation}


مقادیر بالاتر \lr{F1-Score} نشان‌دهنده عملکرد بهتر مدل در دستیابی به تعادل بین صحت و بازخوانی هستند. به عبارت دیگر، مدلی با \lr{F1-Score} بالاتر، قادر است تعداد زیادی از نمونه‌های مثبت را به‌درستی شناسایی کند، در حالی که موارد مثبت کاذب کمتری تولید می‌کند. این ویژگی، \lr{F1-Score} را به معیاری کارآمد برای ارزیابی مدل‌های یادگیری ماشین در مواجهه با داده‌های نامتوازن تبدیل می‌کند. زمانی که توزیع نمونه‌ها در کلاس‌های مختلف نابرابر است، مانند شناسایی تداخلات دارویی، \lr{F1-Score} اطلاعات ارزشمندی در مورد عملکرد مدل فراهم می‌کند \cite{ref_sokolova2009}.

\subsubsection{انواع امتیاز F1}

هنگامی که مدل‌های یادگیری ماشین در مسائل با چندین کلاس ارزیابی می‌شوند، انواع مختلفی از امتیاز F1 برای خلاصه‌سازی عملکرد مدل در تمام کلاس‌ها مورد استفاده قرار می‌گیرد:

\begin{itemize}
	\item \textbf{\lr{Micro F1-Score}}: در این روش، تمامی کلاس‌ها جمع‌بندی می‌شوند و یک \lr{F1-Score} کلی محاسبه می‌شود. این نوع \lr{F1-Score} زمانی کاربرد دارد که تمام کلاس‌ها از اهمیت یکسان برخوردار باشند، بدون در نظر گرفتن اندازه هر کلاس. فرمول آن به‌صورت زیر است:
	\begin{equation}
		F1_{Micro} = 2 \cdot \frac{\text{\LR{Micro Precision}} \cdot \text{\LR{Micro Recall}}}{\text{\LR{Micro Precision}} + \text{\LR{Micro Recall}}}
	\end{equation}
	
	\item \textbf{\lr{Macro F1-Score}}: این روش \lr{F1-Score} را برای هر کلاس به‌طور جداگانه محاسبه کرده و سپس میانگین آن‌ها گرفته می‌شود. این نوع \lr{F1-Score} زمانی استفاده می‌شود که بخواهیم به تمام کلاس‌ها به طور یکسان اهمیت بدهیم و از عدم تعادل کلاس‌ها صرف‌نظر کنیم. فرمول آن به شکل زیر است:
	\begin{equation}
		F1_{Macro} = \frac{1}{N} \sum_{i=1}^{N} F1_i
	\end{equation}	
	
	که در آن \( N \) تعداد کلاس‌ها است.
	
	\item \textbf{\lr{Weighted F1-Score}}: در این نوع، \lr{F1-Score} برای هر کلاس به‌طور جداگانه محاسبه می‌شود و سپس میانگین آن‌ها با توجه به تعداد نمونه‌های هر کلاس وزن‌دهی می‌شود. این روش زمانی مفید است که بخواهیم عدم تعادل در تعداد نمونه‌ها در هر کلاس را در نظر بگیریم. فرمول آن به‌صورت زیر است:
	\begin{equation}
		F1_{Weighted} = \sum_{i=1}^{N} w_i \cdot F1_i
	\end{equation}
	
	که در آن \( w_i \) نسبت نمونه‌های کلاس \( i \) است \cite{ref_manning2008}.
\end{itemize}
تحلیل مقادیر \lr{Micro F1-Score}، \lr{Macro F1-Score} و \lr{Weighted F1-Score} می‌تواند به درک جامع‌تری از توانایی مدل در ایجاد تعادل بین دقت و بازخوانی در کلاس‌های مختلف کمک کند. تفاوت معنادار بین این معیارها می‌تواند نشانه‌ای از عملکرد ناهمگون مدل در کلاس‌های متفاوت باشد.

\subsubsection{استفاده از F1-Score در شناسایی تداخلات دارویی}


در این تحقیق، برای ارزیابی عملکرد مدل در شناسایی و دسته‌بندی تداخلات دارویی به 65 کلاس مختلف، از انواع مختلف \textbf{\lr{F1-Score}} استفاده شده است:

\begin{itemize}
	\item \textbf{\lr{Micro F1-Score}}: برای ارزیابی عملکرد کلی مدل بدون در نظر گرفتن تعادل در اندازه کلاس‌ها.
	\item \textbf{\lr{Macro F1-Score}}: برای ارزیابی عملکرد مدل به‌طور مساوی در تمامی 65 کلاس.
	\item \textbf{\lr{Weighted F1-Score}}: برای در نظر گرفتن عدم تعادل تعداد نمونه‌ها در هر کدام از 65 کلاس.
\end{itemize}

با محاسبه این معیار برای هر یک از 65 نوع تداخل دارویی به‌طور جداگانه، می‌توان تشخیص داد که مدل در کدام کلاس‌ها عملکرد خوبی دارد و در کدام‌ها نیاز به بهبود دارد. داده‌های تداخلات دارویی معمولاً به‌طور نامتوازن هستند. در چنین شرایطی، \textbf{\lr{Weighted F1-Score}} و \textbf{\lr{Per-Class F1-Score}} به درک بهتر عملکرد مدل در تمامی کلاس‌ها کمک می‌کند. همچنین \textbf{\lr{Macro F1-Score}} و \textbf{\lr{Micro F1-Score}} به ارزیابی این موضوع می‌پردازد که آیا مدل به‌طور یکنواخت در تمام انواع تداخلات دارویی عمل می‌کند یا بیشتر به کلاس‌های بزرگ‌تر توجه دارد. این معیارها از آنجا که عملکرد مدل را در برابر داده‌های نامتوازن و متفاوت ارزیابی می‌کنند، ابزار مناسبی برای تحلیل دقیق و جامع شناسایی تداخلات دارویی هستند \cite{ref_sokolova2009}.

با بررسی مقادیر \lr{F1-Score} محاسبه شده برای هر یک از 65 نوع تداخل دارویی، می‌توان انواع تداخلاتی را که مدل در دستیابی به تعادل بین معیارهای صحت و بازخوانی در آن‌ها عملکرد ضعیف‌تری دارد، شناسایی کرد. تمرکز بر بهبود شناسایی این انواع خاص از تداخلات دارویی می‌تواند به ارتقای کارایی کلی سیستم در شناسایی تداخلات دارویی منجر شود. این بهبود عملکرد را می‌توان با اقداماتی مانند تنظیم آستانه تصمیم‌گیری یا استفاده از الگوریتم‌های طبقه‌بندی جایگزین محقق ساخت.

\section{نتیجه‌گیری}
در این پیوست، معیارهای ارزیابی اصلی مورد استفاده در این پژوهش، یعنی دقت و امتیاز F1 به همراه اجزای تشکیل‌دهنده آنها مورد بررسی قرار گرفتند. معیار دقت، عملکرد کلی مدل را از نظر نسبت پیش‌بینی‌های صحیح نشان می‌دهد، در حالی که امتیاز F1 با ترکیب دو معیار صحت و بازخوانی، ارزیابی متوازن‌تری از عملکرد مدل به‌خصوص در مواجهه با داده‌های نامتوازن ارائه می‌کند. در پروژه‌های پیچیده مانند شناسایی تداخلات دارویی که شامل طبقه‌بندی انواع مختلفی از تداخلات است، استفاده از این دو معیار مکمل به درک عمیق‌تر از عملکرد مدل کمک می‌کند. با تحلیل نتایج به دست آمده از این معیارها، پژوهشگران می‌توانند نقاط قوت و ضعف مدل را شناسایی کرده و راهکارهای مناسب را برای بهبود عملکرد آن اتخاذ نمایند. این فرآیند منجر به توسعه مدل‌های دقیق‌تر و کارآمدتری می‌شود که قادر به شناسایی انواع تداخلات دارویی با اطمینان بالاتری هستند.
